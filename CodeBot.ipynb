{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": " Load the API key and relevant Python libaries.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import openai\nopenai.api_key = \"Enter your api key from openai\"\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": " we will use OpenAI's gpt-3.5-turbo model and the chat completions endpoint and load the response.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0, # this is the degree of randomness of the model's output\n    )\n    return response.choices[0].message[\"content\"]\n\ndef get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature, # this is the degree of randomness of the model's output\n    )\n#     print(str(response.choices[0].message))\n    return response.choices[0].message[\"content\"]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "we get the input from user and collect the messages",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def collect_messages(_):\n    prompt = inp.value_input\n    inp.value = ''\n    context.append({'role':'user', 'content':f\"{prompt}\"})\n    response = get_completion_from_messages(context) \n    context.append({'role':'assistant', 'content':f\"{response}\"})\n    panels.append(\n        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n    panels.append(\n        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n \n    return pn.Column(*panels)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "we prompt the codebot to respond from user input and display the options provided by codebot such as generating code or debuging the code or optimising the code.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import panel as pn  # GUI\npn.extension()\n\npanels = [] # collect display \n\ncontext = [ {'role':'system', 'content':\"\"\"\nYou are CodeBot, an automated service to get users request. \\\nYou first greet the user mentioning you are a codebot,then give the options each option to be mentioned in new line\\ \n1.to generate a code\\ \n2.to debug a code\\ \n3.check the performance\\\nand wait until the user enters the option\\\nand then asks if it's to generate a simple code or debug a code or verify it's performance. \\\nYou wait until the user enters his entire request, then ask user to verify it finally \\\nand ask whether he wants to add anything else. \\\nIf it's to generate a code, then ask the user to specify the code needs or comments to enter. \\\nFinally you give the code as per the user request.\\\nYou respond in a short, very conversational friendly style. \\\nThe code options includes \\\ngenerate a code \\\ndebug the given code \\\nperformance good,bad,average \\\n\nif the user enters to debug the code ask the user to enter his code\\\nif the code contains any error address it and ask the user to correct it \\ \nif the users requests about the performance just specify him that the code is good or bad or average\\\nif the performance of the code is bad or average,give me the code with good performance\\\n\"\"\"} ]  # accumulate messages\n\n\ninp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text hereâ€¦')\nbutton_conversation = pn.widgets.Button(name=\"Chat!\")\n\ninteractive_conversation = pn.bind(collect_messages, button_conversation)\n\ndashboard = pn.Column(\n    inp,\n    pn.Row(button_conversation),\n    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n)\n\ndashboard",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}